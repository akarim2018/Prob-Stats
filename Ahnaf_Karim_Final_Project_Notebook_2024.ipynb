{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akarim2018/Prob-Stats/blob/main/Ahnaf_Karim_Final_Project_Notebook_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAr1e9WSJoty"
      },
      "source": [
        "# Final Project Notebook - Spring 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lAvEYy9Sl-3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOGTsXv1WHP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "27e0403c-2de4-4d6d-dcb7-74a6bec2349d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-18-1f3b431a63de>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-1f3b431a63de>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    matplotlib.pyplot as plt\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "from torchvision.models import *\n",
        "from PIL import Image\n",
        "import requests\n",
        "from torchvision import models\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Inline Code for first code segment\n",
        "\n",
        "# Importing the matplotlib.pyplot module to enable plotting graphs and visualizing data effectively.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing the imageio library to read and write a wide range of image data, including animated images, video, and volumetric data.\n",
        "import imageio\n",
        "\n",
        "# Importing the PyTorch library which is used for building deep learning models.\n",
        "import torch\n",
        "\n",
        "# Importing the torchvision library, a package of the PyTorch project that includes popular datasets, model architectures, and common image transformations for computer vision.\n",
        "import torchvision\n",
        "\n",
        "# Importing specific modules from torchvision:\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# Importing numpy, a fundamental package for scientific computing with Python. It provides support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Importing specific pretrained models directly for easy access.\n",
        "from torchvision.models import *\n",
        "\n",
        "# Importing the Image class from PIL (Python Imaging Library) to support opening, manipulating, and saving many different image file formats.\n",
        "from PIL import Image\n",
        "\n",
        "# Importing the requests module to send all kinds of HTTP requests.\n",
        "import requests\n",
        "\n",
        "# Importing model architectures specifically from the torchvision.models module again (redundant import).\n",
        "from torchvision import models\n",
        "\n",
        "# Importing summary from torchsummary, which provides a quick summary of the PyTorch model, showing the layers and parameters.\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "wdlcDugBXWyr",
        "outputId": "14188f0a-46ab-4d42-c5a2-bed5e27bc3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-22-f60efe9fe7fb>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-f60efe9fe7fb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Inline Code for first code segment\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xlCJANl1XRZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXSqNoaoWHQB"
      },
      "outputs": [],
      "source": [
        "def plot(x):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x,cmap='gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(20, 20)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()  # Create a figure and a single subplot\n",
        "    im = ax.imshow(x, cmap='gray')  # Display the image matrix 'x' using a grayscale color map\n",
        "    ax.axis('off')  # Hide the axis to focus only on the image\n",
        "    fig.set_size_inches(20, 20)  # Set the figure size to 20x20 inches for better visibility\n",
        "    plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "T_KQhMzzXsDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4N7peO5WHQD"
      },
      "outputs": [],
      "source": [
        "im = imageio.imread('https://raw.githubusercontent.com/imageio/imageio-binaries/master/images/imageio_banner.png') # read the raw image from the code pulled off the internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rfeaoMLWHQG"
      },
      "outputs": [],
      "source": [
        "plot(im) #plots the defined im function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary module for using the AlexNet model from torchvision\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "# Initializing a pre-trained AlexNet model and transferring it to CUDA device 0\n",
        "# - `alexnet(pretrained=True)`: Loads a pre-trained AlexNet model. Setting `pretrained=True` downloads"
      ],
      "metadata": {
        "id": "Ht6PIzgfYGnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78e6JxupWHQJ"
      },
      "outputs": [],
      "source": [
        "net = alexnet(pretrained=True).cuda(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6P-S3VJWHQL"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.Resize(256),\n",
        "   transforms.CenterCrop(224),\n",
        "   transforms.ToTensor(),\n",
        "   normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the transforms module from torchvision to apply common image transformations\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a normalization transformation using the transforms.Normalize class.\n",
        "# This normalization adjusts image pixel values to have a specified mean and standard deviation,\n",
        "# which is crucial for matching the training conditions of the pre-trained network.\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],  # Mean values for the ImageNet dataset for RGB channels.\n",
        "   std=[0.229, 0.224, 0.225]    # Standard deviations for the ImageNet dataset for RGB channels.\n",
        ")\n",
        "\n",
        "# Define a preprocessing pipeline that combines multiple image transformations\n",
        "# using transforms.Compose. This sequence of transformations is applied to the images before\n",
        "# passing them to the neural network.\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.Resize(256),         # Resizes the input image to 256x256 pixels.\n",
        "   transforms.CenterCrop(224),     # Crops the center of the image to 224x224 pixels, matching the model input size.\n",
        "   transforms.ToTensor(),          # Converts the image to a PyTorch tensor.\n",
        "   normalize                        # Applies the normalization defined earlier.\n",
        "])"
      ],
      "metadata": {
        "id": "bWYyghyUYXm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "I9YcXudRWHQN",
        "outputId": "9e8c1a62-06cb-4f96-ff19-ea652719ae20"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'imageio' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-05f3aa2994ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.medicalnewstoday.com/content/images/articles/322/322868/golden-retriever-puppy.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# defines the url for the imported image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imageio' is not defined"
          ]
        }
      ],
      "source": [
        "im = imageio.imread('https://www.medicalnewstoday.com/content/images/articles/322/322868/golden-retriever-puppy.jpg') # defines the url for the imported image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReOMMcp_WHQQ"
      },
      "outputs": [],
      "source": [
        "plot(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxCazLs9WHQS"
      },
      "outputs": [],
      "source": [
        "image = Image.fromarray(im) #convert to pil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW0MtLokWHQU"
      },
      "outputs": [],
      "source": [
        "img_tensor = preprocess(image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'image' is a PIL Image object loaded previously.\n",
        "# Apply the 'preprocess' transformation pipeline defined earlier to the image.\n",
        "# This process involves resizing, center cropping, converting to tensor, and normalizing the image as per the specified parameters in 'preprocess'.\n",
        "# The result is a tensor representing the image, now suitable for input into a deep learning model.\n",
        "img_tensor = preprocess(image)"
      ],
      "metadata": {
        "id": "aG1ViJmxYshj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMWZ_9KFWHQX"
      },
      "outputs": [],
      "source": [
        "img_tensor = img_tensor.unsqueeze_(0)\n",
        "\n",
        "# The tensor 'img_tensor' represents a preprocessed image that is ready for model input.\n",
        "# However, deep learning models typically expect a batch of data as input, not just a single image.\n",
        "# `unsqueeze_(0)` is used to add an additional dimension at the beginning of the tensor,\n",
        "# turning the shape from [C, H, W] to [1, C, H, W].\n",
        "# This operation modifies the tensor in-place, effectively creating a batch of one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7aFClpbWHQZ"
      },
      "outputs": [],
      "source": [
        "img_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIb-_ZuMWHQb"
      },
      "outputs": [],
      "source": [
        "img_variable = torch.tensor(img_tensor).cuda(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oDi8X2EWHQf"
      },
      "outputs": [],
      "source": [
        "out = net(img_variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjUnQPioWHQl"
      },
      "outputs": [],
      "source": [
        "label_index = out.cpu().data.numpy().argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L45n4KizWHQo"
      },
      "outputs": [],
      "source": [
        "label_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IknOTR23WHQq"
      },
      "outputs": [],
      "source": [
        "top_list = np.flip(np.argsort(out.cpu().data.numpy())[0][-10:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV5AF8U4WHQs"
      },
      "outputs": [],
      "source": [
        "LABELS_URL = 'https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX4oc_13WHQu"
      },
      "outputs": [],
      "source": [
        "labels = {int(key):value for (key, value) in requests.get(LABELS_URL).json().items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "jhkU-BjaWHQw",
        "outputId": "a25b4b05-5a9b-439d-9fe9-be9c61c9d8c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'label_index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4a707554e106>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'label_index' is not defined"
          ]
        }
      ],
      "source": [
        "print(labels[label_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32BmM3u9WHQy"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print(labels[top_list[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7voIWVpWHQ0"
      },
      "outputs": [],
      "source": [
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsSgs1I4WHQ2"
      },
      "outputs": [],
      "source": [
        "summary(net, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1hkZxB5WHQ8"
      },
      "outputs": [],
      "source": [
        "out = net.features[0](img_variable).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdbXfCTrWHQ-"
      },
      "outputs": [],
      "source": [
        "plot(out[0,0,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mAyPUQjWHRA"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(4096),net.classifier[0:6](net.avgpool(net.features[0:13](img_variable)).flatten()).cpu().detach().numpy())\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl5DlTyMWHRI"
      },
      "outputs": [],
      "source": [
        "im = imageio.imread('http://bocasurfcam.com/most_recent_image.php')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8jvmBk1WHRK"
      },
      "outputs": [],
      "source": [
        "plot(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3ka99joWHRM"
      },
      "outputs": [],
      "source": [
        "def load_im(im):\n",
        "    image = Image.fromarray(im) #convert to pil\n",
        "    img_tensor = preprocess(image)\n",
        "    img_tensor = img_tensor.unsqueeze_(0)\n",
        "    img_variable = torch.tensor(img_tensor).cuda(0)\n",
        "    return img_variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U_M65I6WHRO"
      },
      "outputs": [],
      "source": [
        "out = net(load_im(im))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX-aWqumWHRQ"
      },
      "outputs": [],
      "source": [
        "def inference(im):\n",
        "    out = net(load_im(im))\n",
        "    label_index = out.cpu().data.numpy().argmax()\n",
        "    top_list = np.flip(np.argsort(out.cpu().data.numpy())[0][-10:])\n",
        "    print(labels[label_index])\n",
        "    print('____')\n",
        "    for i in range(10):\n",
        "        print(labels[top_list[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApQh6jBFWHRS"
      },
      "outputs": [],
      "source": [
        "inference(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp6wuUf6cirx"
      },
      "source": [
        "# Restart Notebook (Disconnect and Delete Runtime) Before Running Next Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Et1v31JjgF"
      },
      "source": [
        "# Custom Data Deck (AHNAF KARIM) PEN VS PENCIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJjTOJXQY7L2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image\n",
        "!pip install flashtorch\n",
        "import requests\n",
        "from pdf2image import convert_from_path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "from torchvision import *\n",
        "from torchvision.models import *\n",
        "from flashtorch.utils import apply_transforms\n",
        "import wandb as wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcM-MSMRmAXL"
      },
      "outputs": [],
      "source": [
        "def GPU(data):\n",
        "    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=torch.device('cuda'))\n",
        "\n",
        "def GPU_data(data):\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=torch.device('cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0TQftz1WEOU"
      },
      "outputs": [],
      "source": [
        "def plot(x):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x, cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(5, 5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK25ZLwzWFGC"
      },
      "outputs": [],
      "source": [
        "def get_google_slide(url):\n",
        "    url_head = \"https://docs.google.com/presentation/d/1Sj8X-7LdLOOvBO9ispLIlFfOI_RtM-b3O3JIOtibCVs/edit?usp=sharing\"\n",
        "    url_body = url.split('/')[5]\n",
        "    page_id = url.split('.')[-1]\n",
        "    return url_head + url_body + \"/export/pdf?id=\" + url_body + \"&pageid=\" + page_id\n",
        "\n",
        "def get_slides(url):\n",
        "    url = get_google_slide(url)\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('file.pdf', 'wb').write(r.content)\n",
        "    images = convert_from_path('file.pdf', 500)\n",
        "    return images\n",
        "\n",
        "def load(image):\n",
        "\n",
        "    return apply_transforms(image).clone().detach().requires_grad_(True).to(device)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opN3hI0lemBV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "labels = {int(key):value for (key, value) in requests.get('https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json').json().items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxtu0XWiWHpK"
      },
      "outputs": [],
      "source": [
        "model = alexnet(weights='DEFAULT').to(device)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EnZVMTqiqwz"
      },
      "outputs": [],
      "source": [
        "url = \"https://docs.google.com/presentation/d/1Sj8X-7LdLOOvBO9ispLIlFfOI_RtM-b3O3JIOtibCVs/edit?usp=sharing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7MhH8hrR3AE"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "for image in get_slides(url):\n",
        "\n",
        "    plot(image)\n",
        "\n",
        "    images.append(load(image))\n",
        "\n",
        "images = torch.vstack(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKsUVAPdQwmP"
      },
      "outputs": [],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJlgt1avR3I9"
      },
      "outputs": [],
      "source": [
        "model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgGzMREYR3LN"
      },
      "outputs": [],
      "source": [
        "y = model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3NVy8_7T_rb"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsYfYT6UR3Nn"
      },
      "outputs": [],
      "source": [
        "guesses = torch.argmax(y, 1).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSec8rITW7T"
      },
      "outputs": [],
      "source": [
        "for i in list(guesses):\n",
        "    print(labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CALvf79gjAY-"
      },
      "outputs": [],
      "source": [
        "Y = np.zeros(50,)\n",
        "Y[25:] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSF3ICfP04kM"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqvMEcxhY6dl"
      },
      "outputs": [],
      "source": [
        "X = y.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqPB9TKyEJCS"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB9J8q8LEgCG"
      },
      "outputs": [],
      "source": [
        "plt.plot(X[0],'.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pfcg2h51IQr"
      },
      "outputs": [],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaHI4-u_1O87"
      },
      "outputs": [],
      "source": [
        "np.argmax(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEJfAcaM2mdG"
      },
      "outputs": [],
      "source": [
        "labels[948]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3wq2fNM13K9"
      },
      "outputs": [],
      "source": [
        "top_ten = np.argsort(X[0])[::-1][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3awGR9i18os"
      },
      "outputs": [],
      "source": [
        "for i in top_ten:\n",
        "    print(labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXOMKyB_1Zfa"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cetMFwBQngCQ"
      },
      "outputs": [],
      "source": [
        "plt.hist(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBt4rsdIefV_"
      },
      "outputs": [],
      "source": [
        "X = GPU_data(X)\n",
        "Y = GPU_data(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4BlYG-CgC2z"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    s1 = torch.exp(x - torch.max(x,1)[0][:,None])\n",
        "    s = s1 / s1.sum(1)[:,None]\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ-UV8W_c_9o"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(outputs, labels):\n",
        "    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPQjN4JwYHAz"
      },
      "outputs": [],
      "source": [
        "def Truncated_Normal(size):\n",
        "\n",
        "    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2)\n",
        "    u2 = torch.rand(size)\n",
        "    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2)\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW3ttVcq1sI9"
      },
      "outputs": [],
      "source": [
        "def acc(out,y):\n",
        "    with torch.no_grad():\n",
        "        return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UXgio04fyvz"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x79Sie8XKPOC"
      },
      "outputs": [],
      "source": [
        "def get_batch(mode):\n",
        "    b = c.b\n",
        "    if mode == \"train\":\n",
        "        r = np.random.randint(X.shape[0]-b)\n",
        "        x = X[r:r+b,:]\n",
        "        y = Y[r:r+b]\n",
        "    elif mode == \"test\":\n",
        "        r = np.random.randint(X_test.shape[0]-b)\n",
        "        x = X_test[r:r+b,:]\n",
        "        y = Y_test[r:r+b]\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXOr9aM8A8P-"
      },
      "outputs": [],
      "source": [
        "def model(x,w):\n",
        "\n",
        "    return x@w[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzRsuDek9Fve"
      },
      "outputs": [],
      "source": [
        "def make_plots():\n",
        "\n",
        "    acc_train = acc(model(x,w),y)\n",
        "\n",
        "    wb.log({\"acc_train\": acc_train})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Calculate training accuracy using the current batch of data\n",
        "    acc_train = acc(model(x, w), y)  # Assuming 'acc' calculates the accuracy of the model predictions against true labels\n",
        "\n",
        "    # Log the training accuracy to Weights & Biases\n",
        "    wb.log({\"acc_train\": acc_train})  # Use Weights & Biases to log the training accuracy metric"
      ],
      "metadata": {
        "id": "kmpLEcnzZiwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WANJibeUNghZ"
      },
      "outputs": [],
      "source": [
        "wb.init(project=\"Linear_Model_Photo_1\");\n",
        "c = wb.config\n",
        "\n",
        "c.h = 0.001\n",
        "c.b = 4\n",
        "c.epochs = 100000\n",
        "\n",
        "w = [GPU(Truncated_Normal((1000,2)))]\n",
        "\n",
        "optimizer = torch.optim.Adam(w, lr=c.h)\n",
        "\n",
        "for i in range(c.epochs):\n",
        "\n",
        "    x,y = get_batch('train')\n",
        "\n",
        "    loss = cross_entropy(softmax(model(x,w)),y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    wb.log({\"loss\": loss})\n",
        "\n",
        "    make_plots()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.init(project=\"Linear_Model_Photo_1\");\n",
        "c = wb.config\n",
        "\n",
        "c.h = 0.001\n",
        "c.b = 4\n",
        "c.epochs = 100000\n",
        "\n",
        "w = [GPU(Truncated_Normal((1000,2)))]\n",
        "\n",
        "optimizer = torch.optim.Adam(w, lr=c.h)\n",
        "\n",
        "for i in range(c.epochs):\n",
        "\n",
        "    x,y = get_batch('train')\n",
        "\n",
        "    loss = cross_entropy(softmax(model(x,w)),y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    wb.log({\"loss\": loss})\n",
        "\n",
        "    make_plots()"
      ],
      "metadata": {
        "id": "ashPr5oibQCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import wb  # Assuming 'wb' stands for Weights & Biases, you might need to replace 'wb' with 'wandb', the common alias for Weights & Biases\n",
        "\n",
        "# Initialize Weights & Biases for experiment tracking\n",
        "wb.init(project=\"Linear_Model_Photo_1\")\n",
        "\n",
        "# Configuration object for hyperparameters\n",
        "c = wb.config  # Creating a configuration object to store hyperparameters\n",
        "\n",
        "# Hyperparameters for the model\n",
        "c.h = 0.001  # Learning rate for the optimizer\n",
        "c.b = 4      # Batch size (unused in this code snippet, assuming it should be used in get_batch)\n",
        "c.epochs = 100000  # Number of training epochs\n",
        "\n",
        "# Initialize weights using a truncated normal distribution specific to GPU processing\n",
        "w = [GPU(Truncated_Normal((1000,2)))]  # `GPU` and `Truncated_Normal` are placeholders and might require replacement with actual PyTorch calls\n",
        "\n",
        "# Initialize an optimizer for the weights\n",
        "optimizer = torch.optim.Adam(w, lr=c.h)  # Using the Adam optimizer with the learning rate from config\n",
        "\n",
        "# Training loop\n",
        "for i in range(c.epochs):\n",
        "\n",
        "    # Fetching a batch of data\n",
        "    x, y = get_batch('train')  # Assuming get_batch is a function that returns a batch of inputs and labels\n",
        "\n",
        "    # Calculating the loss function\n",
        "    # This snippet assumes that `softmax`, `model`, and `cross_entropy` are defined elsewhere\n",
        "    loss = cross_entropy(softmax(model(x, w)), y)\n",
        "\n",
        "    # Zero the gradients before backward pass\n",
        "    optimizer.zero_grad()  # Reset gradients to zero to prevent accumulation from previous iterations\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()  # Compute the gradient of the loss with respect to all trainable parameters\n",
        "\n",
        "    # Step the optimizer to update model parameters\n",
        "    optimizer.step()  # Update weights based on computed gradients\n",
        "\n",
        "    # Log the loss to Weights & Biases\n",
        "    wb.log({\"loss\": loss})  # Log current loss to Weights & Biases platform for tracking\n",
        "\n",
        "    # Make plots (function undefined here, assuming it plots relevant training metrics)\n",
        "    make_plots()  # Assuming this is a custom function defined to visualize training"
      ],
      "metadata": {
        "id": "mikg93RUZWAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PT1SvIeWSeS"
      },
      "outputs": [],
      "source": [
        "#Code wont load my ppt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cogMnVmoY6fs"
      },
      "outputs": [],
      "source": [
        "\"https://docs.google.com/presentation/d/1Sj8X-7LdLOOvBO9ispLIlFfOI_RtM-b3O3JIOtibCVs/edit#slide=id.g2b78f0cdf85_0_330\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44_in1VIjkRr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}